{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "105de5a7-60f5-496e-a885-1a35b3c88fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Load data and retrain the model ---\n",
      "Model is being retrained with the best parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [22:04:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 2. Calculate SHAP values ---\n",
      "SHAP values calculated.\n",
      "\n",
      "--- 3. Create SHAP Summary Plot ---\n",
      "Summary plot saved at: docs/tuning_results/shap_summary_plot.png\n",
      "\n",
      "--- 4. Create SHAP Dependence Plots and Insights File ---\n",
      "Creating dependence plot for: age_last_milestone_year\n",
      "Creating dependence plot for: milestones\n",
      "Creating dependence plot for: funding_total_usd\n",
      "\n",
      "Insights file created. Please fill in the explanations at: docs/tuning_results/shap_insights.md\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "# --- Configuration and Data Paths ---\n",
    "BEST_PARAMS = {\n",
    "    'subsample': 0.6, \n",
    "    'n_estimators': 400, \n",
    "    'min_child_weight': 1, \n",
    "    'max_depth': 5, \n",
    "    'learning_rate': 0.01, \n",
    "    'colsample_bytree': 0.6\n",
    "}\n",
    "RANDOM_STATE = 42\n",
    "TARGET_COL = \"status\"\n",
    "# Since the files are in the current directory, we only use the name:\n",
    "TRAIN_PATH = 'train_clean.csv' \n",
    "TEST_PATH = 'test_clean.csv'\n",
    "OUTPUT_DIR = 'docs/tuning_results/'  # Target folder for the outputs\n",
    "\n",
    "# Set Matplotlib Backend for saving the plots\n",
    "plt.switch_backend('Agg')\n",
    "\n",
    "def load_data_and_train_model():\n",
    "    \"\"\"Loads the data and retrains the best XGBoost model.\"\"\"\n",
    "    print(\"--- 1. Load data and retrain the model ---\")\n",
    "    try:\n",
    "        # Load data\n",
    "        train_clean = pd.read_csv(TRAIN_PATH)\n",
    "        test_clean  = pd.read_csv(TEST_PATH)\n",
    "        \n",
    "        # Split into X and y (as in Cathy's notebook)\n",
    "        X_train = train_clean.drop(columns=[TARGET_COL])\n",
    "        y_train = train_clean[TARGET_COL]\n",
    "        X_test  = test_clean.drop(columns=[TARGET_COL])\n",
    "        \n",
    "        # Create and train the best model with the found parameters\n",
    "        best_model = XGBClassifier(\n",
    "            **BEST_PARAMS, \n",
    "            random_state=RANDOM_STATE, \n",
    "            eval_metric=\"logloss\", \n",
    "            use_label_encoder=False, \n",
    "            n_jobs=-1\n",
    "        )\n",
    "        print(\"Model is being retrained with the best parameters...\")\n",
    "        best_model.fit(X_train, y_train)\n",
    "        \n",
    "        # Save the model (optional, but useful for subsequent steps)\n",
    "        joblib.dump(best_model, os.path.join(OUTPUT_DIR, 'best_xgboost_model.joblib'))\n",
    "\n",
    "        # SHAP requires the feature names in the DataFrame\n",
    "        return X_test, best_model\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR loading or training: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def run_shap_analysis(X_test, best_model):\n",
    "    \"\"\"Calculates SHAP values and creates the plots and insights.\"\"\"\n",
    "    print(\"\\n--- 2. Calculate SHAP values ---\")\n",
    "    \n",
    "    # SHAP Explainer for tree-based models\n",
    "    explainer = shap.TreeExplainer(best_model)\n",
    "    \n",
    "    # Calculate SHAP values\n",
    "    # We use X_test to explain how predictions are made on the test data.\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "    print(\"SHAP values calculated.\")\n",
    "\n",
    "    # SHAP values here are 2D (n_samples Ã— n_features)\n",
    "    shap_values_class_1 = shap_values  # No need to index 1, since we only have 2 classes.\n",
    "    \n",
    "    # --- 3. Create SHAP Summary Plot (Global Importance) ---\n",
    "    print(\"\\n--- 3. Create SHAP Summary Plot ---\")\n",
    "    try:\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        shap.summary_plot(\n",
    "            shap_values_class_1, \n",
    "            X_test, \n",
    "            show=False,\n",
    "            plot_type=\"dot\", \n",
    "            max_display=10  # Show the top 10 features\n",
    "        )\n",
    "        summary_plot_path = os.path.join(OUTPUT_DIR, 'shap_summary_plot.png')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(summary_plot_path, dpi=300)\n",
    "        plt.close()\n",
    "        print(f\"Summary plot saved at: {summary_plot_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating the summary plot: {e}\")\n",
    "        return\n",
    "    \n",
    "    # --- 4. Create SHAP Dependence Plots (Top 3 Features) and generate insights ---\n",
    "    print(\"\\n--- 4. Create SHAP Dependence Plots and Insights File ---\")\n",
    "    \n",
    "    # Determine the top 3 features based on Mean(|SHAP|)\n",
    "    mean_abs_shap = np.abs(shap_values_class_1).mean(0)  # No need for .values\n",
    "    top_features_indices = np.argsort(mean_abs_shap)[::-1]\n",
    "    feature_names = X_test.columns.to_list()\n",
    "    top_feature_names = [feature_names[i] for i in top_features_indices[:3]]\n",
    "    \n",
    "    insights = [\"# SHAP Insights (Lan)\\n\\n\"]\n",
    "    insights.append(f\"The SHAP analysis of the tuned XGBoost model identifies the following top 3 features that have the greatest influence on the prediction of startup success ({TARGET_COL}):\")\n",
    "    \n",
    "    for feature_name in top_feature_names:\n",
    "        print(f\"Creating dependence plot for: {feature_name}\")\n",
    "        try:\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            shap.dependence_plot(\n",
    "                feature_name,\n",
    "                shap_values_class_1,  # Directly use without .values\n",
    "                X_test,\n",
    "                interaction_index=\"auto\", \n",
    "                show=False,\n",
    "                title=f\"SHAP Dependence Plot: {feature_name}\"\n",
    "            )\n",
    "            dependence_plot_path = os.path.join(OUTPUT_DIR, f\"shap_dependence_{feature_name}.png\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(dependence_plot_path, dpi=300)\n",
    "            plt.close()\n",
    "            \n",
    "            insights.append(f\"\\n## {feature_name}\")\n",
    "            insights.append(f\"**Interpretation (according to Dependence Plot - See {dependence_plot_path}):**\")\n",
    "            insights.append(\"*(Please fill in the detailed observation here, e.g.: 'High values for this feature (red) lead to positive SHAP values, meaning that a higher value increases the likelihood of startup success.')*\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error creating the dependence plot for {feature_name}: {e}\")\n",
    "\n",
    "    # Save the insights\n",
    "    insights_path = os.path.join(OUTPUT_DIR, 'shap_insights.md')\n",
    "    with open(insights_path, 'w') as f:\n",
    "        f.write('\\n'.join(insights))\n",
    "    print(f\"\\nInsights file created. Please fill in the explanations at: {insights_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    \n",
    "    X_test, best_model = load_data_and_train_model()\n",
    "    \n",
    "    if X_test is not None and best_model is not None:\n",
    "        run_shap_analysis(X_test, best_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1f0b83-d6d9-4e79-a2fe-78d425136882",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
