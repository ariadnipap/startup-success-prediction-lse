{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45f335ad",
   "metadata": {},
   "source": [
    "# Evaluation of both pipeline models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e8bcd2",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "Since there is a full classification report from random forest, the classification report will be done manually based on the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "224b0459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Logistic Regression)\n",
      "\n",
      "[[ 39  26]\n",
      " [ 27  93]]\n",
      "\n",
      "Classification Report (Logistic Regression)\n",
      "\n",
      "       Class  Precision     Recall   F1-score    Support\n",
      "------------------------------------------------------------\n",
      "           0       0.59       0.60       0.60         65\n",
      "           1       0.78       0.78       0.78        120\n",
      "------------------------------------------------------------\n",
      "    accuracy                             0.71        185\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Logistic Regression confusion matrix values\n",
    "lr_TN = 39\n",
    "lr_FP = 26\n",
    "lr_FN = 27\n",
    "lr_TP = 93\n",
    "\n",
    "# Confusion matrix array (if you need it)\n",
    "confusion_matrix_lr = np.array([[lr_TN, lr_FP],\n",
    "                                [lr_FN, lr_TP]])\n",
    "\n",
    "print(\"Confusion Matrix (Logistic Regression)\\n\")\n",
    "print(f\"[[{lr_TN:3d} {lr_FP:3d}]\")\n",
    "print(f\" [{lr_FN:3d} {lr_TP:3d}]]\\n\")\n",
    "\n",
    "# Supports (actual class counts)\n",
    "lr_support_0 = lr_TN + lr_FP\n",
    "lr_support_1 = lr_TP + lr_FN\n",
    "lr_total = lr_support_0 + lr_support_1\n",
    "\n",
    "# Class 0 metrics\n",
    "lr_precision_0 = lr_TN / (lr_TN + lr_FN)\n",
    "lr_recall_0 = lr_TN / (lr_TN + lr_FP)\n",
    "lr_f1_0 = 2 * lr_precision_0 * lr_recall_0 / (lr_precision_0 + lr_recall_0)\n",
    "\n",
    "# Class 1 metrics\n",
    "lr_precision_1 = lr_TP / (lr_TP + lr_FP)\n",
    "lr_recall_1 = lr_TP / (lr_TP + lr_FN)\n",
    "lr_f1_1 = 2 * lr_precision_1 * lr_recall_1 / (lr_precision_1 + lr_recall_1)\n",
    "\n",
    "# Accuracy\n",
    "lr_accuracy = (lr_TP + lr_TN) / lr_total\n",
    "\n",
    "# Print simplified classification report\n",
    "print(\"Classification Report (Logistic Regression)\\n\")\n",
    "print(f\"{'Class':>12} {'Precision':>10} {'Recall':>10} {'F1-score':>10} {'Support':>10}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'0':>12} {lr_precision_0:10.2f} {lr_recall_0:10.2f} {lr_f1_0:10.2f} {lr_support_0:10d}\")\n",
    "print(f\"{'1':>12} {lr_precision_1:10.2f} {lr_recall_1:10.2f} {lr_f1_1:10.2f} {lr_support_1:10d}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'accuracy':>12} {'':>10} {'':>10} {lr_accuracy:10.2f} {lr_total:10d}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59b3111",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df73a02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Random Forest)\n",
      "\n",
      "[[ 38  27]\n",
      " [ 19 101]]\n",
      "\n",
      "Classification Report (Random Forest)\n",
      "\n",
      "       Class  Precision     Recall   F1-score    Support\n",
      "------------------------------------------------------------\n",
      "           0       0.67       0.58       0.62         65\n",
      "           1       0.79       0.84       0.81        120\n",
      "------------------------------------------------------------\n",
      "    accuracy                             0.75        185\n"
     ]
    }
   ],
   "source": [
    "# Random Forest confusion matrix values\n",
    "\n",
    "rf_TN = 38\n",
    "rf_FP = 27\n",
    "rf_FN = 19\n",
    "rf_TP = 101\n",
    "\n",
    "# Supports\n",
    "rf_support_0 = rf_TN + rf_FP\n",
    "rf_support_1 = rf_TP + rf_FN\n",
    "\n",
    "# Per-class metrics\n",
    "rf_precision_0 = 0.67\n",
    "rf_recall_0 = 0.58\n",
    "rf_f1_0 = 0.62\n",
    "\n",
    "rf_precision_1 = 0.79\n",
    "rf_recall_1 = 0.84\n",
    "rf_f1_1 = 0.81\n",
    "\n",
    "# Accuracy\n",
    "rf_accuracy = 0.75\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix (Random Forest)\\n\")\n",
    "print(f\"[[{rf_TN:3d} {rf_FP:3d}]\")\n",
    "print(f\" [{rf_FN:3d} {rf_TP:3d}]]\\n\")\n",
    "\n",
    "# Print simplified classification report\n",
    "print(\"Classification Report (Random Forest)\\n\")\n",
    "print(f\"{'Class':>12} {'Precision':>10} {'Recall':>10} {'F1-score':>10} {'Support':>10}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'0':>12} {rf_precision_0:10.2f} {rf_recall_0:10.2f} {rf_f1_0:10.2f} {rf_support_0:10d}\")\n",
    "print(f\"{'1':>12} {rf_precision_1:10.2f} {rf_recall_1:10.2f} {rf_f1_1:10.2f} {rf_support_1:10d}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'accuracy':>12} {'':>10} {'':>10} {rf_accuracy:10.2f} {rf_support_0 + rf_support_1:10d}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a444543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression metrics\n",
    "lr_accuracy = lr_accuracy\n",
    "lr_precision = lr_precision_1\n",
    "lr_recall = lr_recall_1\n",
    "lr_f1 = lr_f1_1\n",
    "\n",
    "# Random Forest metrics\n",
    "rf_accuracy = rf_accuracy\n",
    "rf_precision = rf_precision_1\n",
    "rf_recall = rf_recall_1\n",
    "rf_f1 = rf_f1_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc77154a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: docs/model_comparison.png\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Metrics and values\n",
    "metrics = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"]\n",
    "\n",
    "lr_values = [lr_accuracy, lr_precision, lr_recall, lr_f1]\n",
    "rf_values = [rf_accuracy, rf_precision, rf_recall, rf_f1]\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(x - width/2, lr_values, width, label=\"Logistic Regression\")\n",
    "plt.bar(x + width/2, rf_values, width, label=\"Random Forest\")\n",
    "\n",
    "plt.xticks(x, metrics)\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Model Performance Comparison (Target: status)\")\n",
    "plt.ylim(0,1)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../docs/model_comparison.png\", dpi=200)\n",
    "plt.close()\n",
    "\n",
    "print(\"Saved: docs/model_comparison.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474a2617",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
